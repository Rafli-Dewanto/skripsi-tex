\section{\emph{Vector Similarity Search}}
\emph{Vector similarity search} adalah teknik yang digunakan untuk mengidentifikasi dokumen atau segmen teks yang paling relevan dengan kueri tertentu dengan membandingkan representasi numeriknya, yang dikenal sebagai \emph{embeddings}.~\emph{Embeddings} adalah vektor berdimensi tinggi yang merangkum makna semantik teks, yang dihasilkan oleh model yang dilatih untuk memetakan teks ke urutan numerik~\cite{oshin2024learning}. Dalam konteks LLM, \emph{vector similarity search} sangat penting untuk \emph{retrieval-augmented generation} (RAG), di mana data eksternal diambil untuk memberikan konteks dalam menghasilkan respons yang akurat.
\singlespacing{}
Proses dimulai dengan praproses dokumen, yang melibatkan ekstraksi teks, membaginya menjadi potongan-potongan yang dapat dikelola, dan mengonversi potongan-potongan ini menjadi \emph{embeddings} menggunakan model \emph{embedding}~\cite{oshin2024learning}.~\emph{Embeddings} ini disimpan dalam basis data khusus yang disebut \emph{vector store}, yang dirancang untuk menangani data tidak terstruktur dan melakukan pencarian kesamaan yang efisien. Ketika kueri dikeluarkan, kueri tersebut juga dikonversi menjadi \emph{embedding}, dan \emph{vector store} mengambil \emph{embedding} dokumen yang paling relevan dengan menghitung skor kesamaan. Buku ini menekankan bahwa \emph{vector store}, seperti yang didukung oleh ekstensi Pgvector untuk PostgreSQL, memungkinkan aplikasi yang dapat diskalakan dengan memfasilitasi pengambilan teks yang relevan secara semantik dengan cepat~\cite{oshin2024learning}.
\singlespacing{}
Efektivitas \emph{vector similarity search} terletak pada kemampuannya untuk menangani volume data yang besar, mengatasi keterbatasan jendela konteks dan batas pengetahuan LLM.\@ Dengan mengindeks dokumen dan mengambil hanya potongan yang paling relevan, pendekatan ini memastikan bahwa LLM dapat menghasilkan respons yang terinformasi berdasarkan data eksternal, seperti laporan perusahaan swasta atau informasi terkini yang tidak termasuk dalam data pelatihan mereka~\cite{oshin2024learning}.

\section{\emph{Cosine Similarity}}
\emph{Cosine similarity} adalah metrik yang banyak digunakan untuk mengukur kesamaan antara dua vektor dalam ruang berdimensi tinggi, terutama dalam \emph{vector similarity search}. Metrik ini menghitung kosinus sudut antara dua vektor, menghasilkan nilai antara -1 dan 1, di mana nilai yang lebih dekat ke 1 menunjukkan kesamaan yang lebih besar~\cite{oshin2024learning}. Secara matematis, untuk dua vektor \( \mathbf{A} \) dan \( \mathbf{B} \), \emph{cosine similarity} didefinisikan sebagai:

\[
\mathrm{cosine\ similarity} = \cos(\theta) = \frac{\mathbf{A} \cdot \mathbf{B}}{\|\mathbf{A}\| \|\mathbf{B}\|}
\]

di mana \( \mathbf{A} \cdot \mathbf{B} \) adalah \emph{dot product} dari vektor-vektor tersebut, dan \( \|\mathbf{A}\| \) dan \( \|\mathbf{B}\| \) adalah magnitudenya. Nilai 1 menunjukkan vektor yang identik, 0 menunjukkan tidak ada korelasi, dan -1 menunjukkan arah yang berlawanan.
\singlespacing{}
Dalam konteks \emph{embeddings}, \emph{cosine similarity} mengukur kesamaan semantik antara segmen teks. Misalnya, buku ini mengilustrasikan hal ini dengan \emph{embeddings} hipotetis untuk kata-kata ``pet'', ``dog'', dan ``lion''.~\emph{Embeddings} untuk ``pet'' dan ``dog'' lebih dekat dalam ruang vektor (dengan \emph{cosine similarity} misalnya 0,75) dibandingkan dengan ``pet'' dan ``lion'' (misalnya 0,1), yang mencerminkan kedekatan semantik mereka~\cite{oshin2024learning}.\@ Properti ini memungkinkan \emph{vector store} untuk secara efisien mengidentifikasi dokumen dengan \emph{embeddings} yang paling dekat dengan~\emph{embedding} kueri, memfasilitasi pengambilan yang akurat untuk aplikasi LLM.\@
\singlespacing{}
\emph{Cosine similarity} sangat efektif karena tidak bergantung pada magnitude vektor, hanya fokus pada keselarasan arah mereka. Hal ini membuatnya cocok untuk membandingkan \emph{embeddings} dengan panjang atau skala yang bervariasi, seperti yang dihasilkan oleh model \emph{embedding} yang berbeda. Buku ini menyoroti bahwa \emph{vector store} memanfaatkan \emph{cosine similarity} untuk melakukan kalkulasi kompleks dengan cepat, memungkinkan aplikasi seperti sistem tanya jawab atas dokumen besar, seperti menganalisis risiko dalam laporan tahunan Tesla 2022~\cite{oshin2024learning}.
